{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From\n",
    "https://www.kaggle.com/poonaml/deep-neural-network-keras-way/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84d4608d-4cc3-fcbb-57fb-61f07ad7d020",
    "_uuid": "6407080d145a62b4803d7f159c00118a056a7b5f"
   },
   "source": [
    "*Poonam Ligade*\n",
    "\n",
    "*1st Feb 2017*\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "This notebook is like note to self.\n",
    "\n",
    "I am trying to understand various components of Artificial Neural Networks aka Deep Learning.\n",
    "\n",
    "Hope it might be useful for someone else here.\n",
    "\n",
    "I am designing neural net on MNIST handwritten digits images to identify their correct label i.e number in image.\n",
    "\n",
    "You must have guessed its an image recognition task.\n",
    "\n",
    "MNIST is called Hello world of Deep learning.\n",
    "\n",
    "Lets start!!\n",
    "\n",
    "This notebook is inspired from [Jeremy's][1] [Deep Learning][2] mooc and [Deep learning with python][3] book by Keras author [Fran√ßois Chollet][4] .\n",
    "\n",
    "\n",
    "  [1]: https://www.linkedin.com/in/howardjeremy/\n",
    "  [2]: http://course.fast.ai/\n",
    "  [3]: https://www.manning.com/books/deep-learning-with-python\n",
    "  [4]: https://research.google.com/pubs/105096.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "654456b6-e648-0379-0d66-1cc97af6d00d",
    "_uuid": "6b48ce0e361bdb67689dd2f254ecedd9ade1f5ff"
   },
   "source": [
    "**Import all required libraries**\n",
    "==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e5b02688-c589-5a89-e11c-837c6a99eb6e",
    "_uuid": "f043e48097bfd98e41710142dd8aac41fa88a801"
   },
   "outputs": [],
   "source": [
    "    # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "e5b02688-c589-5a89-e11c-837c6a99eb6e",
    "_uuid": "f043e48097bfd98e41710142dd8aac41fa88a801"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-272d0b6c2052>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# from subprocess import check_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[1;32m--> 336\u001b[1;33m                **kwargs).stdout\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdin'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    707\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    995\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    998\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Lambda, Flatten\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory. \n",
    "# => Changed to data, cuz that's how i role\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"data\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "22a7fd70-ab61-432d-24cb-93e558414495",
    "_uuid": "62fbd0fe9c338b7ac0b04e688c8ee7947e6170f7"
   },
   "source": [
    "**Load Train and Test data**\n",
    "============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "05226b08-226a-1a00-044d-a0e6b2101388",
    "_uuid": "4eff577bcd43479a3b7e91180393cbad9fcfca33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the training & test sets, skipping the header row with [1:]\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "2ec570a6-b41a-2139-5e0e-4941c4f0a9d0",
    "_uuid": "67f0854ad0d812a1395130144a0adef9966fec88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= pd.read_csv(\"data/test.csv\")\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "1ae10fe0-dde9-7659-f53d-1a1bd625cfb1",
    "_uuid": "bdffbed77ce62da528c60e43f2b1bea9f57fcdbc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\n",
    "y_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n",
    "X_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "250b1126-ce1d-6d3f-9736-2504f7a1e098",
    "_uuid": "5e3e1e3574c3e019eadfd14e4dda41fd15b4de2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "e0f15f8a-ac08-540a-58db-dab989cc687c",
    "_uuid": "4c96cf1c9cdc364ae3faff6b8c3c97aa7fa982d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c2c91588-5547-353a-7f92-39600027438e",
    "_uuid": "f01a969286e62fa5ffe37031ed6d4aea947b59a8"
   },
   "source": [
    "The output variable is an integer from 0 to 9. This is a **multiclass** classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60957d82-c76f-4822-28ff-def7011a34fa",
    "_uuid": "da0573528e8c6c3dd2b0e0cf33c600ad3f14466d"
   },
   "source": [
    "## Data Visualization\n",
    "Lets look at 3 images from data set with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28)\n",
      "(42000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# CP investigating...What the next cell does is change each image from 784 columns to 28x28 grid.\n",
    "print(X_train.shape)\n",
    "print(X_train.reshape(X_train.shape[0], 28, 28).shape)\n",
    "\n",
    "# Make plots look better on my dark theme :)\n",
    "COLOR = 'white'\n",
    "plt.rcParams['text.color'] = COLOR\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "plt.rcParams['xtick.color'] = COLOR\n",
    "plt.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "1541678d-a08b-d2b2-1e1e-eabf882baaec",
    "_uuid": "7998af1ce3c065c4a54a73cd97fed9afebde7e96"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Convert train datset to (num_images, img_rows, img_cols) format \n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "\n",
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "6be2f3e9-42eb-85b6-9162-c25e4d706155",
    "_uuid": "4051a0e6612b8e6d4b8aef6a4d131be621cd3a14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand 1 more dimention as 1 for colour channel gray\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "6949468c-fd27-19c5-15c7-0b357a961003",
    "_uuid": "6d4c1323f1fa3f89a16532fed893ec5d72051bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CP: So it added a column with how intense the gray is for each pixel?\n",
    "# That's what it seems like.\n",
    "# 4 dimensional array so it's hard to visualize\n",
    "X_train[X_train[:,:,:] != 0]\n",
    "\n",
    "# Img #0, first pixel (0x0).\n",
    "X_train[0,0,0,0] # Adding anything other than 0 for last index gets error. \n",
    "# So it's one value there, an integer gray scale value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1232c385-3cb2-56fd-4d1d-f027df7bc78e",
    "_uuid": "185d620525e041eb61aabce19e8536614ab50870"
   },
   "source": [
    "**Preprocessing the digit images**\n",
    "=================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6fcc1f9e-1586-e393-49ba-50c73564e0ed",
    "_uuid": "b8847f48f7408c93ce795db16f30c1b7c6a8cf89"
   },
   "source": [
    "**Feature Standardization**\n",
    "-------------------------------------\n",
    "\n",
    "It is important preprocessing step.\n",
    "It is used to centre the data around zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "a3f837ef-0373-8d91-46e6-30992cf73166",
    "_uuid": "528a370b381c91b73131a8c7a4217968278696c8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x): \n",
    "    return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "725c55fc-9742-a63c-9822-c67ab0c773ee",
    "_uuid": "532d3f3bd26b0dfb42bc0c96e9710269234fae9b"
   },
   "source": [
    "*One Hot encoding of labels.*\n",
    "-----------------------------\n",
    "\n",
    "A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the nth digit will be represented as a vector which is 1 in the nth dimension. \n",
    "\n",
    "For example, 3 would be [0,0,0,1,0,0,0,0,0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_cell_guid": "c879f076-b3dd-6cb1-e2d9-2f404f2ed132",
    "_uuid": "41bb3082e71111d73dd0432f9f60261f5be05e15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train= to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP: Makes sense. Instead of each image having a y of 0..10, it's dummy variabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4d76fb04-57fc-e802-6d91-06ece552686b",
    "_uuid": "429e528f5bf36152cd9e0b2acaa457525a202171"
   },
   "source": [
    "Lets plot 10th label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "1c927e75-08d2-d539-54f3-71ab0308fec1",
    "_uuid": "b3ad8362611417de16de730cc55a6ff6309766f4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(y_train[9])\n",
    "plt.plot(y_train[9])\n",
    "plt.xticks(range(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4e130661-9f09-d9a9-d49b-7274ef13927f",
    "_uuid": "40aecbff9b92269d438c384ac429bfa47ab37dda"
   },
   "source": [
    "Oh its 3 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6a89dcdd-7b68-6ed1-2c39-b3a1edb3e7be",
    "_uuid": "dc7ece2b7ee08767b664149d67d922d8c1d0bbb1"
   },
   "source": [
    "**Designing Neural Network Architecture**\n",
    "========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_cell_guid": "39107235-d87a-af4d-44fb-80c9c3aa0212",
    "_uuid": "1070353d05490ccec23933c62f11cdfd2d7e5032",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 43\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a8b65f54-398b-267f-e31a-313210450f54",
    "_uuid": "62606ecbb1d7e259850aebf8a8514e54263a2a06"
   },
   "source": [
    "*Linear Model*\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_cell_guid": "5dbe450c-845f-aaa2-dbde-21414a91d8c1",
    "_uuid": "5f54b59d89cd4e43dd129d9b133950ba83b5cad8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import  Sequential\n",
    "from keras.layers.core import  Lambda , Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c3f674f-f3fc-9614-f2d4-056c3e3ad633",
    "_uuid": "ff25a88562237e84e44f20b38079f2b44a394d2c"
   },
   "source": [
    "Lets create a simple model from Keras Sequential layer.\n",
    "\n",
    "1. Lambda layer performs simple arithmetic operations like sum, average, exponentiation etc.\n",
    "\n",
    " In 1st layer of the model we have to define input dimensions of our data in (rows,columns,colour channel) format.\n",
    " (In theano colour channel comes first)\n",
    "\n",
    "\n",
    "2. Flatten will transform input into 1D array.\n",
    "\n",
    "\n",
    "3. Dense is fully connected layer that means all neurons in previous layers will be connected to all neurons in fully connected layer.\n",
    " In the last layer we have to specify output dimensions/classes of the model.\n",
    " Here it's 10, since we have to output 10 different digit labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP: Keras sequential model = \"a linear stack of layers\"\n",
    "# https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "a2c27783-3cfa-e907-4749-1e340a513f26",
    "_uuid": "fb79b4558335446a722542c8bc06288e96781423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape  (None, 28, 28, 1)\n",
      "output shape  (None, 10)\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Lambda(standardize,input_shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"input shape \",model.input_shape)\n",
    "print(\"output shape \",model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "260645fb-61b7-68e9-6826-047b97436c14",
    "_uuid": "2dd7f371688dd2590de94a94814799654595e55d"
   },
   "source": [
    "***Compile network***\n",
    "-------------------\n",
    "\n",
    "Before making network ready for training we have to make sure to add below things:\n",
    "\n",
    " 1.  A loss function: to measure how good the network is\n",
    "    \n",
    " 2.  An optimizer: to update network as it sees more data and reduce loss\n",
    "    value\n",
    "    \n",
    " 3.  Metrics: to monitor performance of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_cell_guid": "9d1d1af9-b2a8-e3b9-6eaf-100d08fe83aa",
    "_uuid": "4bb75be10b9eec8bcdfe48665f639bf326a5f5fc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CP: LR = learning rate. \n",
    "# RMSprop \"This optimizer is usually a good choice for recurrent neural networks.\"\n",
    "# From linked George Hinton presentation, sounds like a way to speed up learning\n",
    "# https://keras.io/optimizers/\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    " loss='categorical_crossentropy',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_cell_guid": "db3b4be6-4f72-c6cc-65cd-b45978db2462",
    "_uuid": "51f82558d87e95fa5c146b0469ab6c8b42e13bcf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "841a6f3b78b607e142f3e18d88bd7957202e4dcb"
   },
   "source": [
    "## Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "9071d720-da50-8530-e9f3-1f0c37aac7ff",
    "_uuid": "0cff7e02b1ee8894b4ee9080b9268558aaa4e7c5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = X_train\n",
    "y = y_train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches=gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CP take.  \n",
    " .flow: \"Takes data & label arrays, generates batches of augmented data.\"\n",
    "*Augmentation* I think is like modifying images. Darkening and lightening them. Create a more diverse training set. \n",
    "\n",
    "Look at images here: https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "\n",
    "Since in cell above the ImageDataGenerator() class was called with no arguments ..\n",
    "__I think no augmentation has been done on this dataset - yet.__  \n",
    "That happens in a later section.\n",
    "\n",
    "And .flow is moreso used to prepare the images (batch them up?) for fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_cell_guid": "20e08e2a-a394-bb70-69f1-be0fdab4f9ab",
    "_uuid": "6b23c282e2772b1ee482596131d6f1d3494c3bce",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "37800/37800 [==============================] - 146s 4ms/step - loss: 0.2400 - acc: 0.9342 - val_loss: 0.3306 - val_acc: 0.9108\n",
      "Epoch 2/3\n",
      "37800/37800 [==============================] - 156s 4ms/step - loss: 0.2157 - acc: 0.9417 - val_loss: 0.3472 - val_acc: 0.9131\n",
      "Epoch 3/3\n",
      "37800/37800 [==============================] - 146s 4ms/step - loss: 0.2099 - acc: 0.9437 - val_loss: 0.3755 - val_acc: 0.9074\n"
     ]
    }
   ],
   "source": [
    "# CP: Fit generator because it avoids problems with \"fit\" on larger datasets (that can't all be done in memory)\n",
    "# https://medium.com/difference-engine-ai/keras-a-thing-you-should-know-about-keras-if-you-plan-to-train-a-deep-learning-model-on-a-large-fdd63ce66bd2\n",
    "\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_cell_guid": "9f344366-c372-0b04-b7e0-860778d4bfd3",
    "_uuid": "6900e38c62028692b9f101b94730c527129675cc",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_cell_guid": "df40f5fc-586a-1fae-025e-ee508a8d9b71",
    "_uuid": "c4b26ff79e0f186212266b60d03611ad58d0d5e3",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss_values, 'bo')\n",
    "# b+ is for \"blue crosses\"\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_cell_guid": "1ed6b756-00c2-d08c-c596-0ce496ec3d04",
    "_uuid": "fc9be5b885360ca9972e0d6b5da1ea36dc12cb5f",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo')\n",
    "plt.plot(epochs, val_acc_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "64ec304e056ec0c9e33fe94ea2315cbf65a7fbff"
   },
   "source": [
    "## Fully Connected Model\n",
    "\n",
    "Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. \n",
    "Adding another Dense Layer to model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CP: I think these are all cross-validation models, since it's using the batches created from TestTrainSplit  \n",
    "With validation datasets too\n",
    "\n",
    "So author is incrementally trying different (more advanced) models. And moving forward here with a differenr learning rate, add one more dense layer (RELU), change optimizer and metric.  \n",
    "Running just 1 epoch now, not 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "9556f3de5bd370bcddc70a81910eb2104624e3a3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28,28,1)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_uuid": "1901b6805f878ac6ed4efafbaf15bf003d505654",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc = get_fc_model()\n",
    "fc.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_uuid": "5fb346c542c8920fac61ddc5df44b2136969a6e9",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 572s 15ms/step - loss: 0.1621 - acc: 0.9722 - val_loss: 0.5004 - val_acc: 0.9577\n"
     ]
    }
   ],
   "source": [
    "history=fc.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46b81b17854a98f2b380da694691502c1e583bfb"
   },
   "source": [
    "## Convolutional Neural Network\n",
    "CNNs are extremely efficient for images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_uuid": "fd0ab0de6bdbf7addf7515c8d7b59d8d17fef8e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "def get_cnn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28,28,1)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_uuid": "b5baeaed50c9f03c68900461555f4b7831a7e7c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= get_cnn_model()\n",
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "_uuid": "a3d15eeead8b26c41b53d084dc111ae9e667a169",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8657s 229ms/step - loss: 0.0693 - acc: 0.9811 - val_loss: 0.1338 - val_acc: 0.9771\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e2891c7e434a2022ee182a0e9bd243a876532dcc"
   },
   "source": [
    "## Data Augmentation\n",
    "It is tehnique of showing slighly different or new images to neural network to avoid overfitting. And  to achieve better generalization.\n",
    "In case you have very small dataset, you can use different kinds of data augmentation techniques to increase your data size. Neural networks perform better if you provide them more data.\n",
    "\n",
    "Different data aumentation techniques are as follows:\n",
    "1. Cropping\n",
    "2. Rotating\n",
    "3. Scaling\n",
    "4. Translating\n",
    "5. Flipping \n",
    "6. Adding Gaussian noise to input images etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "_uuid": "daa409b92678202cf7c751371b7ba17fb14aa2ac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_uuid": "f21ba7b8d77a37bee6e8238a8f517b654ae3f0a0",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 8456s 224ms/step - loss: 0.1251 - acc: 0.9644 - val_loss: 0.1387 - val_acc: 0.9602\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.001\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "538f504c44e14d389c70b2f35b7225de61b9015d"
   },
   "source": [
    "## Adding Batch Normalization\n",
    "\n",
    "BN helps to fine tune hyperparameters more better and train really deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_uuid": "8b72580fbb06f5f4f769c514cb0d7d2f15aa2c2f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def get_bn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28,28,1)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "_uuid": "78e382d0b3de14312e762edc480b5d215be82269",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 26059s 689ms/step - loss: 0.0351 - acc: 0.9902 - val_loss: 0.0676 - val_acc: 0.9893\n"
     ]
    }
   ],
   "source": [
    "model= get_bn_model()\n",
    "model.optimizer.lr=0.01\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e4b16516a57e152a911f6e7ba7f4d70ff204512"
   },
   "source": [
    "## Submitting Predictions to Kaggle.\n",
    "Make sure you use full train dataset here to train model and predict on test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CP: Observations...\n",
    "* Use full train (X), not X_train, which was a fraction of training from test_train_split. So no validation data going in there.\n",
    "* Go back to 3 epochs instead of 1.\n",
    "* Use the last model, CNN + batch normalization\n",
    "* Unless I'm missing something, we're dumping the augmented image dataset and start over with non-augmented images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "_uuid": "0fc055b482971b36561aaf9421c8a9c53df2900b",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "42000/42000 [==============================] - 27970s 666ms/step - loss: 0.0151 - acc: 0.9980\n",
      "Epoch 2/3\n",
      "42000/42000 [==============================] - 29862s 711ms/step - loss: 0.0225 - acc: 0.9983\n",
      "Epoch 3/3\n",
      "42000/42000 [==============================] - 28848s 687ms/step - loss: 0.0252 - acc: 0.9982\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.01\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X, y, batch_size=64)\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "_cell_guid": "c2841d54-f3dd-1ee8-a30d-4457dec0a67a",
    "_uuid": "4262c6bfb15ec96993e83bd2a2552eadf14fb33d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"DR.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0e6213b0-fc56-658d-46e3-4a5dcb7148ce",
    "_uuid": "3a9a548a2080ebf61b2ce35db78f0c9520c1358c"
   },
   "source": [
    "More to come . Please upvote if you find it useful.\n",
    "\n",
    "You can increase number of epochs on your GPU enabled machine to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Test accuracy on Kaggle leaderboard was : 0.99042  \n",
    "  \n",
    "Compare to train accuracy above. Knowing that CV validation-set accuracy would've been less than that, and test less than that...  \n",
    "  \n",
    "The Kaggle leaderboard is stupid, of course. A) It's a playground competition. Dunno when they will use the rest of the Test dataset (private leaderboard). B) So many people have gamed the test dataset to get 100% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
